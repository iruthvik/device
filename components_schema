import org.apache.spark.sql.types._

val schema = StructType(Seq(
  StructField("ucgDeviceName", StringType, nullable = true),
  StructField("ucgJsonData", StructType(Seq(
    StructField("components", StructType(Seq(
      StructField("component", MapType(StringType, StructType(Seq(
        StructField("name", StringType, nullable = true),
        StructField("transceiver", StructType(Seq(
          StructField("physical-channels", StructType(Seq(
            StructField("channel", MapType(StringType, StructType(Seq(
              StructField("index", StringType, nullable = true),
              StructField("state", StructType(Seq(
                StructField("description", StringType, nullable = true),
                StructField("input-power", StructType(Seq(
                  StructField("instant", IntegerType, nullable = true)
                )), nullable = true),
                StructField("laser-bias-current", StructType(Seq(
                  StructField("instant", IntegerType, nullable = true)
                )), nullable = true),
                StructField("output-power", StructType(Seq(
                  StructField("instant", IntegerType, nullable = true)
                )), nullable = true),
                StructField("target-output-power", IntegerType, nullable = true),
                StructField("tx-laser", BooleanType, nullable = true)
              )), nullable = true)
            )), nullable = true)
          )), nullable = true)
        )), nullable = true)
      )), nullable = true)
    )), nullable = true),
    StructField("timestamp", LongType, nullable = true)
  )), nullable = true),
  StructField("ucgMessage", StringType, nullable = true),
  StructField("ucgSequenceNum", StringType, nullable = true),
  StructField("ucgSource", StringType, nullable = true),
  StructField("ucgTimestamp", StringType, nullable = true),
  StructField("ucgTopic", StringType, nullable = true),
  StructField("ucgType", StringType, nullable = true),
  StructField("ucgYangTopic", StringType, nullable = true)
))


import org.apache.spark.sql.functions._

val df = spark.read.schema(schema).json("path/to/json/file")

// To extract the "state" field inside a dynamic component and channel field, we can use the getItem function with a string argument
val explodedDF = df.select(explode($"ucgJsonData.components.component").as("component"), $"ucgJsonData.timestamp")
  .select($"component._1".as("component"), explode($"component._2.transceiver.physical-channels.channel").as("channel"), $"timestamp")
  .select($"component", $"channel._1".as("channel"), $"channel._2.state".as("state"), $"timestamp")

// To print the "description" field inside the "state" field for all components and channels:
explodedDF.select($"component", $"channel", $"state.description").show()

-------------
import org.apache.spark.sql.types._

val schema = StructType(Seq(
  StructField("ucgDeviceName", StringType, nullable = true),
  StructField("ucgJsonData", StructType(Seq(
    StructField("components", StructType(Seq(
      StructField("component", MapType(
        StringType,
        StructType(Seq(
          StructField("name", StringType, nullable = true),
          StructField("transceiver", StructType(Seq(
            StructField("physical-channels", StructType(Seq(
              StructField("channel", MapType(
                StringType,
                StructType(Seq(
                  StructField("index", StringType, nullable = true),
                  StructField("state", StructType(Seq(
                    StructField("description", StringType, nullable = true),
                    StructField("input-power", StructType(Seq(
                      StructField("instant", IntegerType, nullable = true)
                    )), nullable = true),
                    StructField("laser-bias-current", StructType(Seq(
                      StructField("instant", IntegerType, nullable = true)
                    )), nullable = true),
                    StructField("output-power", StructType(Seq(
                      StructField("instant", IntegerType, nullable = true)
                    )), nullable = true),
                    StructField("target-output-power", IntegerType, nullable = true),
                    StructField("tx-laser", BooleanType, nullable = true)
                  )), nullable = true)
                )),
                valueContainsNull = true
              ))
            )))
          )))
        )),
        valueContainsNull = true
      ))
    ))),
    StructField("timestamp", LongType, nullable = true)
  )), nullable = true),
  StructField("ucgMessage", StringType, nullable = true),
  StructField("ucgSequenceNum", StringType, nullable = true),
  StructField("ucgSource", StringType, nullable = true),
  StructField("ucgTimestamp", StringType, nullable = true),
  StructField("ucgTopic", StringType, nullable = true),
  StructField("ucgType", StringType, nullable = true),
  StructField("ucgYangTopic", StringType, nullable = true)
))
---
import org.apache.spark.sql.functions._

// assume your JSON data is stored in a file called "input.json"
val df = spark.read.json("input.json")

// select the necessary columns from the JSON structure
val selectedDF = df.select(
  col("ucgDeviceName"),
  col("ucgJsonData.components.component"),
  col("ucgJsonData.timestamp")
)

// explode the map column to create separate rows for each key-value pair
val explodedDF = selectedDF.select(
  col("ucgDeviceName"),
  explode(col("component")).as(Seq("component_key", "component_value")),
  col("timestamp")
)

// extract the necessary fields from the nested structure
val finalDF = explodedDF.select(
  col("ucgDeviceName"),
  col("component_key"),
  col("component_value.transceiver.physical-channels.channel"),
  col("timestamp")
).withColumn("channel_key", explode(col("channel")))
 .select(
   col("ucgDeviceName"),
   col("component_key").as("component"),
   col("channel_key").as("channel"),
   col("channel[channel_key].state.description").as("description"),
   col("channel[channel_key].state.input-power.instant").as("input_power_instant"),
   col("channel[channel_key].state.laser-bias-current.instant").as("laser_bias_current_instant"),
   col("channel[channel_key].state.output-power.instant").as("output_power_instant"),
   col("channel[channel_key].state.target-output-power").as("target_output_power"),
   col("channel[channel_key].state.tx-laser").as("tx_laser"),
   col("timestamp")
 )
 
finalDF.show()

