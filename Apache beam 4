import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
import json
import logging

class ValidateAndFilterJson(beam.DoFn):
    def process(self, element):
        try:
            record = json.loads(element)
            
            # Check if the record contains the necessary fields
            if 'ucgDeviceName' in record and 'ucgJsonData' in record:
                ucg_json_data = record['ucgJsonData']
                if 'interfaces' in ucg_json_data and 'interface' in ucg_json_data['interfaces']:
                    yield element
            else:
                logging.warning("Filtered out record without expected schema: %s", record)
        except json.JSONDecodeError:
            logging.error("Failed to decode JSON: %s", element)

class ParseJson(beam.DoFn):
    def process(self, element):
        try:
            record = json.loads(element)
            parsed_records = []
            
            ucg_device_name = record.get('ucgDeviceName')
            ucg_source = record.get('ucgSource', '')
            ucg_type = record.get('ucgType', '')
            timestamp = int(record['ucgJsonData'].get('timestamp', 0))

            interfaces = record['ucgJsonData']['interfaces']['interface']
            
            for interface_name, interface_data in interfaces.items():
                state_counters = interface_data.get('state', {}).get('counters', {})
                parsed_record = {
                    'ucgDeviceName': ucg_device_name,
                    'ucgSource': ucg_source,
                    'ucgType': ucg_type,
                    'timestamp': timestamp,
                    'interface': interface_name,
                    'in_broadcast_pkts': state_counters.get('in-broadcast-pkts', 0),
                    'in_discards': state_counters.get('in-discards', 0),
                    'in_errors': state_counters.get('in-errors', 0),
                    'in_fcs_errors': state_counters.get('in-fcs-errors', 0),
                    'in_multicast_pkts': state_counters.get('in-multicast-pkts', 0),
                    'in_octets': state_counters.get('in-octets', 0),
                    'in_pause_pkts': state_counters.get('in-pause-pkts', 0),
                    'in_pkts': state_counters.get('in-pkts', 0),
                    'in_unicast_pkts': state_counters.get('in-unicast-pkts', 0),
                    'in_unknown_protos': state_counters.get('in-unknown-protos', 0),
                    'out_broadcast_pkts': state_counters.get('out-broadcast-pkts', 0),
                    'out_discards': state_counters.get('out-discards', 0),
                    'out_errors': state_counters.get('out-errors', 0),
                    'out_multicast_pkts': state_counters.get('out-multicast-pkts', 0),
                    'out_octets': state_counters.get('out-octets', 0),
                    'out_pause_pkts': state_counters.get('out-pause-pkts', 0),
                    'out_pkts': state_counters.get('out-pkts', 0),
                    'out_unicast_pkts': state_counters.get('out-unicast-pkts', 0),
                    'out_unknown_protos': state_counters.get('out-unknown-protos', 0)
                }
                parsed_records.append(parsed_record)

            return parsed_records
        except Exception as e:
            logging.error("Error processing record: %s", e)
            return []

class FormatJson(beam.DoFn):
    def process(self, element):
        formatted_record = json.dumps(element)
        yield formatted_record

def run():
    input_file = 'gs://<your-input-bucket>/<your-input-file>.json'
    output_file = 'gs://<your-output-bucket>/<your-output-file>'

    pipeline_options = PipelineOptions()
    p = beam.Pipeline(options=pipeline_options)

    (
        p
        | 'ReadFromGCS' >> beam.io.ReadFromText(input_file)
        | 'ValidateAndFilterJson' >> beam.ParDo(ValidateAndFilterJson())
        | 'ParseJson' >> beam.ParDo(ParseJson())
        | 'FormatJson' >> beam.ParDo(FormatJson())
        | 'WriteToGCS' >> beam.io.WriteToText(output_file, file_name_suffix='.json')
    )

    result = p.run()
    result.wait_until_finish()

if __name__ == '__main__':
    run()
